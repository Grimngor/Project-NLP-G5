{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pickle\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mktmi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download stopwords if not already downloaded\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>donald trump sends out embarrassing new year‚s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>drunk bragging trump staffer started russian c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>sheriff david clarke becomes an internet joke ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>trump is so obsessed he even has obama‚s name ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>pope francis just called out donald trump duri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34147</th>\n",
       "      <td>1</td>\n",
       "      <td>tears in rain as thais gather for late king's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34148</th>\n",
       "      <td>1</td>\n",
       "      <td>pyongyang university needs non-u.s. teachers a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34149</th>\n",
       "      <td>1</td>\n",
       "      <td>philippine president duterte to visit japan ah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34150</th>\n",
       "      <td>1</td>\n",
       "      <td>japan's abe may have won election\\tbut many do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34151</th>\n",
       "      <td>1</td>\n",
       "      <td>demoralized and divided: inside catalonia's po...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34152 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                               text\n",
       "0          0  donald trump sends out embarrassing new year‚s...\n",
       "1          0  drunk bragging trump staffer started russian c...\n",
       "2          0  sheriff david clarke becomes an internet joke ...\n",
       "3          0  trump is so obsessed he even has obama‚s name ...\n",
       "4          0  pope francis just called out donald trump duri...\n",
       "...      ...                                                ...\n",
       "34147      1  tears in rain as thais gather for late king's ...\n",
       "34148      1  pyongyang university needs non-u.s. teachers a...\n",
       "34149      1  philippine president duterte to visit japan ah...\n",
       "34150      1  japan's abe may have won election\\tbut many do...\n",
       "34151      1  demoralized and divided: inside catalonia's po...\n",
       "\n",
       "[34152 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('training_data_lowercase.csv', sep='\\t', names=['label', 'text'])\n",
    "# Print dataset\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check and clean dataset\n",
    "df.dropna(subset=['text', 'label'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess text (lowercasing, removing punctuation, and stopwords)\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    stop_words = set(stopwords.words('english'))  # Using English stopwords\n",
    "    return ' '.join([word for word in text.split() if word not in stop_words])\n",
    "\n",
    "df['cleaned_text'] = df['text'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with empty 'cleaned_text' after preprocessing\n",
    "df = df[df['cleaned_text'].str.strip() != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9027676087274857\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.90      3497\n",
      "           1       0.90      0.91      0.90      3332\n",
      "\n",
      "    accuracy                           0.90      6829\n",
      "   macro avg       0.90      0.90      0.90      6829\n",
      "weighted avg       0.90      0.90      0.90      6829\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Vectorize text using TF-IDF\n",
    "tfidf = TfidfVectorizer(max_features=1000)\n",
    "X = tfidf.fit_transform(df['cleaned_text'])\n",
    "y = df['label']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Logistic Regression model\n",
    "logreg_model = LogisticRegression(max_iter=1000)\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = logreg_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Save the Logistic Regression model and the TF-IDF vectorizer for future use\n",
    "with open('logreg_model.pkl', 'wb') as f:\n",
    "    pickle.dump(logreg_model, f)\n",
    "\n",
    "with open('tfidf_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tfidf, f)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: donald trump sends out embarrassing new year‚s eve message; this is disturbing\n",
      "Actual Label: 0 | Predicted Label: 0\n",
      "--------------------------------------------------\n",
      "Text: drunk bragging trump staffer started russian collusion investigation\n",
      "Actual Label: 0 | Predicted Label: 0\n",
      "--------------------------------------------------\n",
      "Text: sheriff david clarke becomes an internet joke for threatening to poke people ‚in the eye‚\n",
      "Actual Label: 1 | Predicted Label: 1\n",
      "--------------------------------------------------\n",
      "Text: trump is so obsessed he even has obama‚s name coded into his website (images)\n",
      "Actual Label: 1 | Predicted Label: 1\n",
      "--------------------------------------------------\n",
      "Text: pope francis just called out donald trump during his christmas speech\n",
      "Actual Label: 1 | Predicted Label: 1\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Display a few actual vs predicted examples\n",
    "for i in range(5):\n",
    "    print(f\"Text: {df['text'].iloc[i]}\")\n",
    "    print(f\"Actual Label: {y_test.iloc[i]} | Predicted Label: {y_pred[i]}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words for Machine-translated sentences:\n",
      "video\n",
      "breaking\n",
      "gop\n",
      "hillary\n",
      "hillarys\n",
      "racist\n",
      "bernie\n",
      "wow\n",
      "muslim\n",
      "tweets\n",
      "\n",
      "Top 10 words for Human-translated sentences:\n",
      "pm\n",
      "china\n",
      "urges\n",
      "house\n",
      "probe\n",
      "seeks\n",
      "talks\n",
      "us\n",
      "factbox\n",
      "says\n"
     ]
    }
   ],
   "source": [
    "# Import Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize and train Logistic Regression model\n",
    "logreg_model = LogisticRegression(max_iter=1000)\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "# Get the importance of words from the model's coefficients\n",
    "top_n = 10  # Number of top words to display\n",
    "sorted_items = logreg_model.coef_[0].argsort()  # Sort the coefficients by importance\n",
    "\n",
    "# Get the feature names (words)\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "\n",
    "# Display top words for class 0 (e.g., machine-translated sentences)\n",
    "print(f\"Top {top_n} words for Machine-translated sentences:\")\n",
    "for i in sorted_items[:top_n]:\n",
    "    print(f\"{feature_names[i]}\")\n",
    "\n",
    "# Display top words for class 1 (e.g., human-translated sentences)\n",
    "print(f\"\\nTop {top_n} words for Human-translated sentences:\")\n",
    "for i in sorted_items[-top_n:]:\n",
    "    print(f\"{feature_names[i]}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
